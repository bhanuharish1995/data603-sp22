{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw07.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Importing all the useful libraries"
      ],
      "metadata": {
        "id": "9-_-Bd6p_LXT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark\n",
        "import pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTdqOKN7KCjD",
        "outputId": "37c3be91-1540-4e3a-b23d-1447a68f1197"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.7/dist-packages (3.2.1)\n",
            "Requirement already satisfied: py4j==0.10.9.3 in /usr/local/lib/python3.7/dist-packages (from pyspark) (0.10.9.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import *"
      ],
      "metadata": {
        "id": "OByLucV4RNWQ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import mean,when\n",
        "import pyspark.sql.functions as F\n",
        "import pyspark.sql.types as T\n",
        "from pyspark.sql.types import DoubleType\n",
        "from pyspark.ml.feature import StringIndexer\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.classification import GBTClassifier\n",
        "from pyspark.mllib.evaluation import MulticlassMetrics\n",
        "import matplotlib.pyplot as plt\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
        "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit, CrossValidator\n",
        "from pyspark.mllib.classification import LogisticRegressionWithLBFGS\n",
        "from pyspark.mllib.util import MLUtils\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import Imputer,OneHotEncoder"
      ],
      "metadata": {
        "id": "ItCbuTnyk7BT"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "960TUSPZfDSa"
      },
      "outputs": [],
      "source": [
        "spark = SparkSession.builder.getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "spark = pyspark.sql.SparkSession.builder.getOrCreate()\n",
        "sc = spark.sparkContext"
      ],
      "metadata": {
        "id": "QhtZMk6NfFU0"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "mld_SAeRki1z",
        "outputId": "1c80614f-c785-42c4-a9bf-d2aa06f9f685"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7fc95347f390>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://31fa36d2c349:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.2.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wschema = StructType([\n",
        "StructField('Date',StringType(), True),\n",
        "StructField('Location',StringType(), True),\n",
        "StructField('MinTemp',FloatType(), True),\n",
        "StructField('MaxTemp',FloatType(), True),\n",
        "StructField('Rainfall',FloatType(), True),\n",
        "StructField('Evaporation',FloatType(), True),\n",
        "StructField('Sunshine',FloatType(), True),\n",
        "StructField('WindGustDir',StringType(), True),\n",
        "StructField('WindGustSpeed',IntegerType(), True),\n",
        "StructField('WindDir9am',StringType(), True),\n",
        "StructField('WindDir3pm',StringType(), True),\n",
        "StructField('WindSpeed9am',IntegerType(), True),\n",
        "StructField('WindSpeed3pm',IntegerType(), True),\n",
        "StructField('Humidity9am',IntegerType(), True),\n",
        "StructField('Humidity3pm',IntegerType(), True),\n",
        "StructField('Pressure9am',FloatType(), True),\n",
        "StructField('Pressure3pm',FloatType(), True),\n",
        "StructField('Cloud9am',IntegerType(), True),\n",
        "StructField('Cloud3pm',IntegerType(), True),\n",
        "StructField('Temp9am',FloatType(), True),\n",
        "StructField('Temp3pm',FloatType(), True),\n",
        "StructField('RainToday',StringType(), True),\n",
        "StructField('RainTomorrow',StringType(), True)])"
      ],
      "metadata": {
        "id": "hsuEUe_-Ts1I"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Declaring schema for the file\n"
      ],
      "metadata": {
        "id": "IQQXens0_X9k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.csv('weatherAUS.csv',schema=wschema, header = True)"
      ],
      "metadata": {
        "id": "eaOnb0tTkk6u"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.select([count(when(isnull(c), c)).alias(c) for c in df.columns]).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qfeMYdHkni-",
        "outputId": "e1380bcb-3879-4397-d239-ef5bb9d23da1"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+--------+-------+-------+--------+-----------+--------+-----------+-------------+----------+----------+------------+------------+-----------+-----------+-----------+-----------+--------+--------+-------+-------+---------+------------+\n",
            "|Date|Location|MinTemp|MaxTemp|Rainfall|Evaporation|Sunshine|WindGustDir|WindGustSpeed|WindDir9am|WindDir3pm|WindSpeed9am|WindSpeed3pm|Humidity9am|Humidity3pm|Pressure9am|Pressure3pm|Cloud9am|Cloud3pm|Temp9am|Temp3pm|RainToday|RainTomorrow|\n",
            "+----+--------+-------+-------+--------+-----------+--------+-----------+-------------+----------+----------+------------+------------+-----------+-----------+-----------+-----------+--------+--------+-------+-------+---------+------------+\n",
            "|   0|       0|   1485|   1261|    3261|      62790|   69835|          0|        10263|         0|         0|        1767|        3062|       2654|       4507|      15065|      15028|   55888|   59358|   1767|   3609|        0|           0|\n",
            "+----+--------+-------+-------+--------+-----------+--------+-----------+-------------+----------+----------+------------+------------+-----------+-----------+-----------+-----------+--------+--------+-------+-------+---------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dropping the columns having more null values "
      ],
      "metadata": {
        "id": "6VdHgGU6_qKD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop('Evaporation','Sunshine','Cloud9am','Cloud3pm')"
      ],
      "metadata": {
        "id": "mJrQ58eFUfPH"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Used imputer to fill the null values"
      ],
      "metadata": {
        "id": "HYAv4kn4AEvo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Updating the numeric column's null values with their respective mean "
      ],
      "metadata": {
        "id": "VR6MBtcCFgYj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "imputer = Imputer(inputCols=[\"MinTemp\", \"MaxTemp\",\"Rainfall\",\"WindGustSpeed\",\"WindSpeed9am\",\"WindSpeed3pm\",\n",
        "                             \"Humidity9am\",\"Humidity3pm\",\"Pressure9am\",\"Pressure3pm\",\"Temp9am\",\"Temp3pm\"],outputCols=[\"indMinTemp\", \"indMaxTemp\",\"indRainfall\",\"indWindGustSpeed\",\"indWindSpeed9am\",\"indWindSpeed3pm\",\n",
        "                             \"indHumidity9am\",\"indHumidity3pm\",\"indPressure9am\",\"indPressure3pm\",\"indTemp9am\",\"indTemp3pm\"])\n",
        "model = imputer.fit(df)\n",
        "\n",
        "df=model.transform(df)"
      ],
      "metadata": {
        "id": "XIbr3KNqk5SN"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dropping the columns with the null values after imputing"
      ],
      "metadata": {
        "id": "d2AKgHmSdHbq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=df.drop(\"MinTemp\", \"MaxTemp\",\"Rainfall\",\"Win2dGustSpeed\",\"WindSpeed9am\",\"WindSpeed3pm\",\n",
        "                             \"Humidity9am\",\"Humidity3pm\",\"Pressure9am\",\"Pressure3pm\",\"Temp9am\",\"Temp3pm\")"
      ],
      "metadata": {
        "id": "1KWs2oUTVJM2"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Updating with null values of the string columns with relevant data"
      ],
      "metadata": {
        "id": "vkF6cJoSdYSV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.withColumn(\"WindGustDir\",F.when(F.col(\"WindGustDir\") == 'NA','N').otherwise(F.col(\"WindGustDir\")))\n",
        "df = df.withColumn(\"WindDir9am\",F.when(F.col(\"WindDir9am\") == 'NA','N').otherwise(F.col(\"WindDir9am\")))\n",
        "df = df.withColumn(\"WindDir3pm\",F.when(F.col(\"WindDir3pm\") == 'NA','N').otherwise(F.col(\"WindDir3pm\")))\n",
        "df = df.withColumn(\"RainToday\",F.when(F.col(\"RainToday\") == 'NA','No').otherwise(F.col(\"RainToday\")))\n",
        "df = df.withColumn(\"RainTomorrow\",F.when(F.col(\"RainTomorrow\") == 'NA','No').otherwise(F.col(\"RainTomorrow\")))"
      ],
      "metadata": {
        "id": "REZw1ac0lCMf"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking whether the data is having any null values"
      ],
      "metadata": {
        "id": "7gcVsH-cdk52"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.select([count(when(isnull(c), c)).alias(c) for c in df.columns]).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9W0UYT7blGLU",
        "outputId": "e21c609f-265f-404e-f2e8-7d1410c43a97"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+--------+-----------+----------+----------+---------+------------+----------+----------+-----------+----------------+---------------+---------------+--------------+--------------+--------------+--------------+----------+----------+\n",
            "|Date|Location|WindGustDir|WindDir9am|WindDir3pm|RainToday|RainTomorrow|indMinTemp|indMaxTemp|indRainfall|indWindGustSpeed|indWindSpeed9am|indWindSpeed3pm|indHumidity9am|indHumidity3pm|indPressure9am|indPressure3pm|indTemp9am|indTemp3pm|\n",
            "+----+--------+-----------+----------+----------+---------+------------+----------+----------+-----------+----------------+---------------+---------------+--------------+--------------+--------------+--------------+----------+----------+\n",
            "|   0|       0|          0|         0|         0|        0|           0|         0|         0|          0|               0|              0|              0|             0|             0|             0|             0|         0|         0|\n",
            "+----+--------+-----------+----------+----------+---------+------------+----------+----------+-----------+----------------+---------------+---------------+--------------+--------------+--------------+--------------+----------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_col = ['indMinTemp','indMaxTemp','indRainfall','indWindGustSpeed','indWindSpeed9am','indWindSpeed3pm','indHumidity9am','indHumidity3pm','indPressure9am','indHumidity3pm','indHumidity9am','indPressure3pm']"
      ],
      "metadata": {
        "id": "_yjJYvUOlI4e"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Creating a pipeline and using StringIndexer and Onehotencoder "
      ],
      "metadata": {
        "id": "9t-k8CRLFuP1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
        "from pyspark.ml.feature import OneHotEncoder\n",
        "\n",
        " \n",
        "categoricalColumns = [\"WindGustDir\",\"WindDir9am\",\"WindDir3pm\",\"RainToday\",\"RainTomorrow\"]\n",
        "stages = [] # stages in Pipeline\n",
        "for categoricalCol in categoricalColumns:\n",
        "    # Category Indexing with StringIndexer\n",
        "    stringIndexer = StringIndexer(inputCol=categoricalCol, outputCol=categoricalCol + \"Index\")\n",
        "    # Use OneHotEncoder to convert categorical variables into binary SparseVectors\n",
        "    encoder = OneHotEncoder(inputCols=[stringIndexer.getOutputCol()], outputCols=[categoricalCol + \"classVec\"])\n",
        "    stages += [stringIndexer, encoder]\n"
      ],
      "metadata": {
        "id": "NMYWr13UlQAO"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assemblerInputs = [c + \"classVec\" for c in categoricalColumns] + numeric_col\n",
        "assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n",
        "stages += [assembler]"
      ],
      "metadata": {
        "id": "21Du0x1lldte"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decision Tree"
      ],
      "metadata": {
        "id": "g-XvplmN68yl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dt = DecisionTreeClassifier(labelCol='RainTomorrowIndex' , featuresCol=\"features\")"
      ],
      "metadata": {
        "id": "QG8fESGXlgFf"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parameters for decision tree"
      ],
      "metadata": {
        "id": "CSJZE8At7KG4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "paramGrid = (ParamGridBuilder()\n",
        "               .addGrid(dt.impurity, [\"gini\",\"entropy\"])\n",
        "             .addGrid(dt.maxDepth, [5])\n",
        "             .addGrid(dt.maxBins, [5, 10, 15])\n",
        "             .addGrid(dt.minInfoGain, [0.0, 0.2, 0.4])\n",
        "             .build())"
      ],
      "metadata": {
        "id": "McxaqXG2liGO"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator = BinaryClassificationEvaluator().setLabelCol(\"RainTomorrowIndex\")"
      ],
      "metadata": {
        "id": "9tiEqw_slj1j"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Crossvalidator with 4 folds"
      ],
      "metadata": {
        "id": "GXihNL3O7R0b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cv = CrossValidator(estimator = dt,\n",
        "                      estimatorParamMaps = paramGrid,\n",
        "                      evaluator = evaluator,\n",
        "                      numFolds = 4)"
      ],
      "metadata": {
        "id": "hfEd2NRIll1t"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding cv to the stages"
      ],
      "metadata": {
        "id": "r5RccBKgWdYK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stages += [cv]"
      ],
      "metadata": {
        "id": "YsQK2mytln5q"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Splitting the data into train and test data"
      ],
      "metadata": {
        "id": "IDMaItqr7cMV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(trainingData, testData) = df.randomSplit([0.8, 0.2], seed=12345)"
      ],
      "metadata": {
        "id": "Qq5Zrw9mlprV"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Running the pipeline after assigning all the stages "
      ],
      "metadata": {
        "id": "bpgcths47gBQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "partialPipeline = Pipeline().setStages(stages)\n",
        "pipelineModel = partialPipeline.fit(trainingData)\n",
        "preppedDataDF = pipelineModel.transform(testData)"
      ],
      "metadata": {
        "id": "e5IF4QmdZDy3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=pipelineModel.stages[-1].bestModel"
      ],
      "metadata": {
        "id": "5oxLPdDyraHw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "id": "AZSYy5vycjy0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = preppedDataDF.select('RainTomorrowIndex','probability').rdd.map(lambda row: (float(row['probability'][1]), float(row['RainTomorrowIndex'])))"
      ],
      "metadata": {
        "id": "63T846jICs26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = BinaryClassificationMetrics(preds)\n"
      ],
      "metadata": {
        "id": "p46x9jm9ScwF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ROC and AUC"
      ],
      "metadata": {
        "id": "MFvvUbAxTQba"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Area under PR = %s\" % metrics.areaUnderPR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzgiTD2JSjfa",
        "outputId": "c0e0d471-ad2e-4b69-d5ae-2a527485ff37"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Area under PR = 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Area under ROC = %s\" % metrics.areaUnderROC)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fA8FG-mcSqpn",
        "outputId": "9cad6da4-6650-4c1b-a0fd-2557d6387513"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Area under ROC = 1.0\n"
          ]
        }
      ]
    }
  ]
}